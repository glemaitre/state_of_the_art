\section{Discussion} \label{sec:discussion}

\subsection{Brief comparison}

%--------------------------------------------------------------------------------------------------------------------

\begin{figure}
\centering
	\begin{tikzpicture}[scale=.5,every node/.style={scale=0.5}]

\def\labels{
{\color{semiAuto}[10]},
{\color{semiAuto}[11]},
{\color{semiAuto}[41]}
}

\def\reward{75,80,65}
\def\dbSize{25,188,NA}
\def\dbClass{1,3,0}		
\def\cZoom{3} 
\def\percentageLabelAngle{90}
\def\nbeams{3}
\pgfmathsetmacro\beamAngle{(360/\nbeams)}
\pgfmathsetmacro\halfAngle{(180/\nbeams)}
%\def\globalRotation{10}
\pgfmathsetmacro\globalRotation{\halfAngle}

% draw manual AOV results
%\filldraw[blue!15!white,even odd rule] (0,0) circle [radius={\cZoom*.852}] (0,0) circle [radius={\cZoom*.8}];
%\draw[thin,color=blue!50!white,dashed] (0,0) circle [radius={\cZoom*.852}] (0,0) circle [radius={\cZoom*.8}];

%\foreach \x in {.125,.25, ...,1} { \draw[thin]  (0,0) circle [radius={2*\x}]; }
% draw the radiants
\foreach \n  [count=\ni] in \labels
{
\pgfmathsetmacro\cAngle{{(\ni*(360/\nbeams))+\globalRotation}}
\draw	(\cAngle:{\cZoom*1.15})  node[fill=white] {\n};
\draw [thin] (0,0) -- (\cAngle:{\cZoom*1}) ;

}

% draw the % rings 
\foreach \x in {12.5,25, ...,100} 
\draw [thin,color=gray!50] (0,0) circle [radius={\cZoom*\x/100}];

\foreach \x in {50,75,100}
{ 
     \draw [thin,color=black!50] (0,0) circle [radius={\cZoom/100*\x}];
     \foreach \a in {0, 180} \draw ({\percentageLabelAngle+\a}:{\cZoom*0.01*\x}) node  [inner sep=0pt,outer sep=0pt,fill=white,font=\fontsize{8}{8.5}\selectfont]{$\x\%$};
}

% draw the path of the percentages
\def\aux{{\reward}}
\pgfmathsetmacro\origin{\aux[\nbeams-1]} 
\draw [blue, thick] (\globalRotation:{\cZoom*\origin/100}) \foreach \n  [count=\ni] in \reward { -- ({(\ni*(360/\nbeams))+\globalRotation}:{\cZoom*\n/100}) } ;

% label all the percentags
\foreach \n [count=\ni] in \dbSize 
{
	\pgfmathsetmacro\cAngle{{(\ni*(360/\nbeams))+\globalRotation}}
	\pgfmathsetmacro\nreward{\aux[\ni-1]}
	\draw (\cAngle:{\cZoom*1.4}) node[align=center] {{\color{blue}\nreward $\%$} \\ {\color{red}\n} };
} ;

% draw the database rose
\def\dbScale{\9}
\foreach \n [count=\ni] in \dbClass
\filldraw[fill=red!20!white, draw=red!50!black]
(0,0) -- ({\ni*(360/\nbeams)-\halfAngle+\globalRotation}:{\cZoom*\n/9}) arc ({\ni*(360/\nbeams)-\halfAngle+\globalRotation}:{\ni*(360/\nbeams)+\halfAngle+\globalRotation}:{\cZoom*\n/9}) -- cycle;
\foreach \x in {1,2,3}
\draw [thin,color=red!50!black,dashed] (0,0) circle [radius={\cZoom*\x/9}];

%% draw the domain of each class 
  \def\puta{	3/0/{Multiparametric}}
%\def\putaa{  	2/9/{Other+ML},
%  			3/11/{ML},
%  			2/14/{ML+ACM}}

\foreach \numElm/\contadorQueNoSeCalcular/\name [count=\ni] in \puta
 {

 	\pgfmathsetmacro\initialAngle{(\contadorQueNoSeCalcular*\beamAngle)+\halfAngle+\globalRotation}
 	\pgfmathsetmacro\finalAngle  {((\numElm+\contadorQueNoSeCalcular)*\beamAngle)+\halfAngle+\globalRotation}
	\pgfmathsetmacro\l  {\cZoom*1.5+.3pt}
	\draw (\initialAngle:{\cZoom*1.6}) -- (\initialAngle:{\cZoom*1.1});
	\draw [ |<->|,>=latex] (\initialAngle:\l) arc (\initialAngle:\finalAngle:\l) ;    									 
	\pgfmathsetmacro\r  {\cZoom*1.5+.45pt}
    	{\draw [decoration={raise=4pt,text along path,  text={\name},text align={center}},decorate] (\finalAngle:\r) arc (\finalAngle:\initialAngle:\r);}
  }
%  
%   \foreach \numElm/\contadorQueNoSeCalcular/\name [count=\ni] in \putaa
% {
%
% 	\pgfmathsetmacro\initialAngle{(\contadorQueNoSeCalcular*\beamAngle)+\halfAngle+\globalRotation}
% 	\pgfmathsetmacro\finalAngle  {((\numElm+\contadorQueNoSeCalcular)*\beamAngle)+\halfAngle+\globalRotation}
%	\pgfmathsetmacro\l  {\cZoom*1.5+.3pt}
%	\draw (\initialAngle:{\cZoom*1.6}) -- (\initialAngle:{\cZoom*1.1});
%	\draw [ |<->|,>=latex] (\initialAngle:\l) arc (\initialAngle:\finalAngle:\l) ;    									 
%	\pgfmathsetmacro\r  {\cZoom*1.5+.7pt}
%    	{\draw [decoration={text along path, text={\name},text align={center}},decorate] (\initialAngle:\r) arc (\initialAngle:\finalAngle:\r);}    			 
%  }
        
\end{tikzpicture}
\caption{Comparison in term of \ac{froc} of the methods using data from 3.0 Tesla \ac{mri} scanner. The blue value represent the metric and are graphically reported in the blue curve in the center of the figure. The red value correspond to the number of patients in the dataset and is also reported in the center of the figure. The numbers between brackets correspond to the reference as reported in Tab. \ref{tab:sumpap}.}
\label{fig:froc}
\end{figure}

As discussed previously in Sect. \ref{subsubsec:eval}, different metrics have been used to report results. A comparison of the different methods reviewed is given depending on the metric used in each research and also the type of \ac{mri} scanner used (cf., 1.5 \textit{versus} 3.0 Tesla). For each research, the experiment obtaining the best result was reported into these figures.

The results given in term of \ac{auc}-\ac{roc} are depicted in Fig. \ref{fig:auc}. The results vary between $77\%$ and $95\%$ for some experiment with a 1.5 \ac{mri} Tesla scanner and $77\%$ and $95\%$ with a 3.0 Tesla \ac{mri} scanner. 

The results related with sensitivity and specificity are reported in Fig. \ref{fig:sensspec}. In the case that the data were collected with a 1.5 Tesla \ac{mri} scanner, the sensitivity is ranging from $74\%$ and $100\%$ and the specificity from $43\%$ and $93\%$. For the experiments carried out with a 3.0 Tesla \ac{mri} scanner, the sensitivity is varying from $60\%$ to $90\%$ and the specificity from $66\%$ to $99\%$.

Three studies also use \ac{froc} analysis to report their results and are shown in Fig. \ref{fig:froc}. The results are ranging from $65\%$ to $80\%$

However, we would like to emphasize the fact that the results obtained from these different experiments cannot be fairly compared. Different datasets were used implying different complexity involved and set of input parameter during the data acquisition. To our mind, the only to provide a real and fair comparison would be to provide a common working dataset where those algorithms could be tested.

\subsection{General discussion}

This review leads to some general discussions which could direct to future avenues for research. As previously mentioned, no open multi-parametric dataset is currently available. This fact leads to an impossibility to fairly compare the different algorithms designed over years. Also, the availability of a full multi-parametric dataset (cf., \ac{mri} and \ac{mrsi}), could lead to the development of algorithms which use all the different modalities currently available. Recalling Tab. \ref{tab:sumpap}, it can be noted that none of the current works provide a solution using at the same time the four different modalities. We can also mention that all the algorithms are focused on one type of scanner only, either 1.5 Tesla and 3.0 Tesla. A dataset including both these types of imaging could allow to develop more generic algorithms.

Then, by analysing the different stages of the \ac{cad} work-flow, it can be noticed that the actual \ac{cad} systems do not include all the different pre-processing steps. It could be interesting to evaluate the improvement using these pre-processing steps on the final results obtained after the classification. Regarding segmentation and registration of the prostate, \ac{cad} systems could highly benefit from specific research in these areas which could lead to a better automation of those system. Moreover, other methods specific to segmentation and registration which are not actually used in \ac{cad} systems could also perform better than the one currently used in \acp{cad}.

Regarding the classification framework, it seems that the current well-known pattern recognition methods have been widely studied. However, more investigations should be carried out regarding the feature detection stage. Lately, histogram-based features have shown good capabilities in the field of computer vision and could be further investigated. Only one study by \cite{Liu2013} used some of these features.

An important point allowing a fair comparison between methods resides in the fact that no universal evaluation model and metric has been defined by the research community allowing such comparison. Usually, it is quite common to choose an evaluation model which fits the dataset limitations, usually the size. Regarding the evaluation, the community would benefit from settling a standard metric which fairly represents the most performance of the algorithms designed.

Finally, we would like to focus the intention of the reader on the availability of a multi-parametric dataset from 1.5 and 3.0 Tesla \ac{mri} provided by the authors of this review. This dataset can be available at the following webpage address: \texttt{http://visor.udg.edu/dataset}. The dataset is composed of the four modalities discussed in this review with the corresponding ground-truth.